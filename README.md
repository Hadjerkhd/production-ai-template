# ðŸš€ Modern AI Full-Stack Template


<p>
  <img src="https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi" alt="FastAPI">
  <img src="https://img.shields.io/badge/LangChain-1C3C3C?style=for-the-badge&logo=chainlink&logoColor=white" alt="LangChain">
  <img src="https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=Streamlit&logoColor=white" alt="Streamlit">
  <img src="https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white" alt="Docker">
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python">
  <img src="https://img.shields.io/badge/uv-Astral-purple?style=for-the-badge" alt="uv">
</p>

This is a production-ready template for building full-stack AI applications using modern Python tooling.

## Tech Stack

- **FastAPI**: High-performance backend API framework.
- **LangChain**: Framework for building LLM applications (using LCEL).
- **Streamlit**: Rapid frontend development for data apps.
- **UV**: Extremely fast Python package installer and resolver.
- **Docker**: Containerization for consistent deployment.
- **Ruff & Mypy**: Advanced linting and type checking.

## Project Structure

```
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routes/         # API route handlers
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ config.py       # Configuration and environment variables
â”‚   â”œâ”€â”€ schemas/            # Pydantic models for request/response
â”‚   â”œâ”€â”€ services/           # Business logic and specialized services (LLM, etc.)
â”‚   â””â”€â”€ main.py             # Application entry point
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ app.py              # Streamlit frontend application
â”œâ”€â”€ .env.example            # Example environment variables
â”œâ”€â”€ Dockerfile              # Docker image definition
â”œâ”€â”€ docker-compose.yml      # Docker Compose configuration
â”œâ”€â”€ pyproject.toml          # Dependencies and project metadata
â””â”€â”€ uv.lock                 # Lock file for reproducible installs
```

## Prerequisites

- [uv](https://github.com/astral-sh/uv)
- [Docker](https://www.docker.com/) (optional, for containerized run)
- Python 3.9+

## Configuration

1. Copy the example environment file:
   ```bash
   cp .env.example .env
   ```
2. Edit `.env` and add your API keys (e.g., `OPENAI_API_KEY`) if you plan to use real LLM providers.

## Quick Start (Local)

1. **Install dependencies**:
   ```bash
   uv sync
   ```

2. **Start the Backend**:
   ```bash
   uv run uvicorn app.main:app --reload
   ```
   - API Docs: [http://localhost:8000/docs](http://localhost:8000/docs)

3. **Start the Frontend** (in a new terminal):
   ```bash
   uv run streamlit run ui/app.py
   ```
   - UI: [http://localhost:8501](http://localhost:8501)

## Quick Start (Docker)

You can run the entire stack (Backend + Frontend) using Docker.

1. **Build and Run**:
   ```bash
   docker-compose up --build
   ```
   - API Docs: [http://localhost:8000/docs](http://localhost:8000/docs)
   - Frontend UI: [http://localhost:8501](http://localhost:8501)

## Development

- **Linting & Formatting**:
  ```bash
  uv run ruff check . --fix
  uv run ruff format .
  ```
- **Type Checking**:
  ```bash
  uv run mypy .
  ```
